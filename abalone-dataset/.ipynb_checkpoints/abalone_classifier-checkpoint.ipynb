{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "\n",
    "np.random.seed(1234) # Seed fix \n",
    "\n",
    "def randomize():\n",
    "    np.random.seed(time.time())  #use this method if we need to reset the random\n",
    "    \n",
    "    \n",
    "#Hyper parameters \n",
    "RND_MEAN = 0\n",
    "RND_STD = 0.0030 \n",
    "LEARNING_RATE= 0.001 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abalone_exec_main(epoch_count=10, mb_size=10, report=1):\n",
    "    load_abalone_dataset() #Read data set \n",
    "    init_model()\n",
    "    train_and_test(epoch_count, mb_size, report)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_abalone_dataset():\n",
    "    file_path = './abalone.csv'\n",
    "    with open(file_path) as csvfile:\n",
    "        csvreader=csv.reader(csvfile) #read a file \n",
    "        next(csvreader, None) # Skip the first line \n",
    "        rows = [] #rows list \n",
    "        for row in csvreader:\n",
    "            rows.append(row)  #keep adding .. \n",
    "            \n",
    "        global data, input_cnt, output_cnt\n",
    "        input_cnt, output_cnt = 10, 1  #input vec size, output vec size \n",
    "        \n",
    "        \n",
    "        #print (len(rows))\n",
    "        #print (input_cnt+output_cnt)\n",
    "        # num of data from csv * num feature + output   = 4177 * 11 matrix \n",
    "        \n",
    "        data = np.zeros([len(rows), input_cnt+output_cnt])\n",
    "        \n",
    "        #one hot vectorize for Sex : M,F,I \n",
    "        for n,row in enumerate(rows):\n",
    "            if row[0] == 'I': \n",
    "                data[n,0] = 1 \n",
    "            elif row[0] == 'M':\n",
    "                data[n,1] = 1\n",
    "            elif row[0] == 'F':\n",
    "                data[n,2] = 1 \n",
    "            #data 3rd colum to end will be filled with csv 1st colum (without sex) to end \n",
    "            data[n, 3:] = row[1:]\n",
    "                    \n",
    "        #print(rows)\n",
    "        print(\"오오 잘된다\")\n",
    "        print(data)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오오 잘된다\n",
      "[[ 0.      1.      0.     ...  0.101   0.15   15.    ]\n",
      " [ 0.      1.      0.     ...  0.0485  0.07    7.    ]\n",
      " [ 0.      0.      1.     ...  0.1415  0.21    9.    ]\n",
      " ...\n",
      " [ 0.      1.      0.     ...  0.2875  0.308   9.    ]\n",
      " [ 0.      0.      1.     ...  0.261   0.296  10.    ]\n",
      " [ 0.      1.      0.     ...  0.3765  0.495  12.    ]]\n"
     ]
    }
   ],
   "source": [
    "load_abalone_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    global weight,bias, input_cnt, output_cnt\n",
    "    weight = np.random.normal(RND_MEAN, RND_STD, [input_cnt, output_cnt])\n",
    "    bias = np.zeros(output_cnt)\n",
    "    \n",
    "    print(weight)\n",
    "    print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.41430549e-03]\n",
      " [-3.57292708e-03]\n",
      " [ 4.29812091e-03]\n",
      " [-9.37955688e-04]\n",
      " [-2.16176620e-03]\n",
      " [ 2.66148882e-03]\n",
      " [ 2.57876524e-03]\n",
      " [-1.90957051e-03]\n",
      " [ 4.70891163e-05]\n",
      " [-6.72805486e-03]]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run training and evaluation function \n",
    "def train_and_test(epoch_count, mb_size, report):\n",
    "    step_count = arrange_data(mb_size)\n",
    "    test_x, test_y = get_test_data() \n",
    "    \n",
    "    for epoch in range(epoch_count):\n",
    "        losses, accs= [],[]\n",
    "        \n",
    "        for n in range(step_count): \n",
    "            train_x, train_y = get_train_data(mb_size, n)\n",
    "            loss, acc = run_train(train_x, train_y)\n",
    "            \n",
    "            #add loss to losses \n",
    "            losses.append(loss)\n",
    "            #add accuracy to accuracies \n",
    "            acces.append(acc)\n",
    "            \n",
    "        if report > 0 and (epoch+1) % report == 0:\n",
    "            acc = run_test(test_x, test_y)\n",
    "            #printout 5width , point 100th digits\n",
    "            print('Epoch {}: loss={:5.3f}, accuracy={:5.3f}/{:5.3f}'.format(epoch+1, np.mean(losses), np.mean(accs),acc))\n",
    "    \n",
    "    final_acc = run_test(test_x, test_y)\n",
    "    print('')\n",
    "    print('Final Test: final accuracy = {:5.3f}'.format(final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle and divide data set into two (training, and evaluation)\n",
    "\n",
    "def arrange_data(mb_size):\n",
    "    global data, shuffle_map, test_begin_idx\n",
    "    \n",
    "    #print(data.shape[0])\n",
    "    shuffle_map = np.arange(data.shape[0])   # Y.shape is (n,m) , Y,shape[0] is n , arange \n",
    "    #0,1,2,...4177\n",
    "    \n",
    "    print(shuffle_map)\n",
    "    np.random.shuffle(shuffle_map)\n",
    "    \n",
    "    #shuffle it !\n",
    "    print(shuffle_map)\n",
    "    \n",
    "    step_count = int(data.shape[0] * 0.8) // mb_size\n",
    "    test_begin_idx = step_count * mb_size \n",
    "    \n",
    "    \n",
    "    #print(step_count)\n",
    "    #print(test_begin_idx)\n",
    "    \n",
    "    return step_count \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 4174 4175 4176]\n",
      "[3108 2694 3185 ... 3126 3356 3900]\n",
      "334\n",
      "3340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrange_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    global data, shuffle_map, test_begin_idx, output_cnt\n",
    "    \n",
    "    test_data = data[shuffle_map[test_begin_idx:]]  # Test data -> starting from 33410, data.\n",
    "    print(test_data)\n",
    "    \n",
    "    return test_data[:, :-output_cnt], test_data[:, -output_cnt:] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(mb_size, nth):\n",
    "    global data, shuffle_map, test_begin_idx, output_cnt\n",
    "    if nth == 0: #if this is first epoch call , nth ==0, \n",
    "        np.random.shuffle(shuffle_map[:test_begin_idx])\n",
    "        print(shuffle_map[:test_begin_idx])\n",
    "    \n",
    "    train_data = data[shuffle_map[mb_size*nth: mb_size*(nth+1)]]\n",
    "    return train_data[:,:-output_cnt], train_data[:, -output_cnt:]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 756  665 4144 ... 3445 3154 1864]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.    , 1.    , 0.    , 0.615 , 0.525 , 0.155 , 1.1375, 0.367 ,\n",
       "         0.236 , 0.37  ],\n",
       "        [0.    , 0.    , 1.    , 0.395 , 0.295 , 0.095 , 0.2245, 0.078 ,\n",
       "         0.054 , 0.08  ],\n",
       "        [0.    , 1.    , 0.    , 0.67  , 0.535 , 0.19  , 1.669 , 0.7465,\n",
       "         0.2935, 0.508 ],\n",
       "        [1.    , 0.    , 0.    , 0.54  , 0.42  , 0.14  , 0.6275, 0.2505,\n",
       "         0.1175, 0.235 ],\n",
       "        [0.    , 0.    , 1.    , 0.615 , 0.515 , 0.135 , 1.1215, 0.545 ,\n",
       "         0.2305, 0.29  ],\n",
       "        [1.    , 0.    , 0.    , 0.37  , 0.275 , 0.14  , 0.2215, 0.097 ,\n",
       "         0.0455, 0.0615],\n",
       "        [0.    , 0.    , 1.    , 0.5   , 0.375 , 0.115 , 0.5945, 0.185 ,\n",
       "         0.148 , 0.19  ],\n",
       "        [0.    , 1.    , 0.    , 0.55  , 0.41  , 0.13  , 0.8705, 0.4455,\n",
       "         0.2115, 0.213 ],\n",
       "        [0.    , 1.    , 0.    , 0.5   , 0.375 , 0.15  , 0.636 , 0.2535,\n",
       "         0.145 , 0.19  ],\n",
       "        [0.    , 1.    , 0.    , 0.6   , 0.46  , 0.155 , 0.9595, 0.4455,\n",
       "         0.189 , 0.295 ]]), array([[20.],\n",
       "        [10.],\n",
       "        [11.],\n",
       "        [ 9.],\n",
       "        [ 9.],\n",
       "        [ 6.],\n",
       "        [11.],\n",
       "        [ 9.],\n",
       "        [10.],\n",
       "        [11.]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_train_data(10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(x,y):\n",
    "    output, aux_nn = forward_neuralnet(x)  #output = martix * weight + b , aux_nn is original x \n",
    "    loss, aux_pp = forward_postproc(output,y) #loss -> MSE result , aux_pp -> differences\n",
    "    #aux_nn , aux_pp keep these information for back propagation\n",
    "    \n",
    "    accuracy = eval_accuracy(output,y)\n",
    "    \n",
    "    G_loss =1.0  #loss gradient = 1 \n",
    "    G_output = backprop_postproc(G_loss, aux_pp)\n",
    "    backprop_neuralnet(G_output, aux_nn)\n",
    "    \n",
    "    return loss, accuracy \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(x,y):\n",
    "    output, _ = forward_neuralnet(x)\n",
    "    accuracy = eval_accuracy(output,y)\n",
    "    return accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_neuralnet(x):\n",
    "    global weight, bias\n",
    "    output = np.matmul(x,weight) + bias  # input matrix * weight and + b \n",
    "    return output, x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_postproc(output, y):\n",
    "    diff = output - y\n",
    "    square = np.square(diff) # diff ^2 \n",
    "    loss = np.mean(square)   # MSE \n",
    "    return loss, diff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpro_postproc(G_loss, diff):\n",
    "    shape = diff.shape  #tuple (n,m)\n",
    "    \n",
    "    g_loss_square = np.ones(shape) / np.prod(shape)\n",
    "    g_square_diff = 2* diff\n",
    "    g_diff_output = 1\n",
    "    \n",
    "    G_square = g_loss_square * G_loss\n",
    "    G_diff = g_square_diff * Gsquare\n",
    "    G_output = g_diff_output * G_diff \n",
    "    \n",
    "    return G_output \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_neuralnet(G_output, x):\n",
    "    global weight, bias \n",
    "    g_output_w = x.transpose()\n",
    "    \n",
    "    G_w = np.matmul(g_output_w, G_output)\n",
    "    G_b = np.sum(G_output, axis=0)\n",
    "    \n",
    "    weight -= LEARNING_RATE * G_w\n",
    "    bias -= LEARNING_RATE * G_b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
